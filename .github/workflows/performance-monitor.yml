name: Performance Monitoring

on:
  schedule:
    - cron: '0 0 * * 1'  # Run every Monday at midnight
  workflow_dispatch:  # Allow manual triggering
  push:
    branches:
      - main
    paths:
      - 'src/**'

env:
  NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
  NEXT_PUBLIC_SUPABASE_ANON_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY }}
  SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}

jobs:
  lighthouse-check:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      issues: write
      
    steps:
      - uses: actions/checkout@v3.5.3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3.8.1
        with:
          node-version: '18'
          
      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 8
          
      - name: Install dependencies
        run: |
          pnpm install
          npm install -g @lhci/cli@0.12.x
          
      - name: Build application
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_ANON_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: pnpm build
        
      - name: Start Next.js server
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_ANON_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          pnpm start &
          echo "Waiting for Next.js server to be ready..."
          sleep 20  # Give more time for the server to fully start
          
      - name: Run Lighthouse CI
        run: |
          echo "Starting Lighthouse CI..."
          mkdir -p .lighthouseci
          
          if [[ "${{ github.event_name }}" == "schedule" ]]; then
            BASE_URL="https://qogent.in"
          else
            BASE_URL="http://localhost:3000"
          fi
          
          echo "Testing URL: $BASE_URL"
          
          # Test if the server is responding
          curl -I $BASE_URL
          
          # Run Lighthouse CI with verbose logging
          lhci collect --verbose --url=$BASE_URL --config=.github/lighthouse-config.json
          lhci assert --config=.github/lighthouse-config.json
        continue-on-error: true
        id: lighthouse
        
      - name: Debug Lighthouse output
        run: |
          echo "Checking .lighthouseci directory contents:"
          ls -la .lighthouseci/
          
      - name: Format Lighthouse Score
        id: format-score
        run: |
          REPORT_PATH=$(find .lighthouseci -name "*.json" | head -n 1)
          if [ ! -f "$REPORT_PATH" ]; then
            echo "No Lighthouse report found in directory:"
            ls -la .lighthouseci/
            exit 1
          fi
          
          echo "Found report at: $REPORT_PATH"
          echo "Report contents:"
          cat "$REPORT_PATH"
          
          echo "PERFORMANCE_SCORE=$(jq '.categories.performance.score' $REPORT_PATH)" >> $GITHUB_ENV
          echo "ACCESSIBILITY_SCORE=$(jq '.categories.accessibility.score' $REPORT_PATH)" >> $GITHUB_ENV
          echo "SEO_SCORE=$(jq '.categories.seo.score' $REPORT_PATH)" >> $GITHUB_ENV
          echo "BEST_PRACTICES_SCORE=$(jq '.categories.["best-practices"].score' $REPORT_PATH)" >> $GITHUB_ENV
          
      - name: Store Lighthouse report
        uses: actions/upload-artifact@v4
        with:
          name: lighthouse-report
          path: .lighthouseci
          retention-days: 30
          
      - name: Create Issue on Low Scores
        if: env.PERFORMANCE_SCORE < 0.9 || env.ACCESSIBILITY_SCORE < 0.9 || env.SEO_SCORE < 0.9 || env.BEST_PRACTICES_SCORE < 0.9
        uses: actions/github-script@v6.4.1
        with:
          script: |
            try {
              const scores = {
                Performance: (process.env.PERFORMANCE_SCORE * 100).toFixed(1),
                Accessibility: (process.env.ACCESSIBILITY_SCORE * 100).toFixed(1),
                SEO: (process.env.SEO_SCORE * 100).toFixed(1),
                'Best Practices': (process.env.BEST_PRACTICES_SCORE * 100).toFixed(1)
              };
              
              const lowScores = Object.entries(scores)
                .filter(([_, score]) => score < 90)
                .map(([category, score]) => `- ${category}: ${score}%`)
                .join('\n');
              
              const issue = await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: 'ðŸš¨ Lighthouse Performance Alert',
                body: `## Performance Monitoring Alert
                
                The following scores are below the 90% threshold:
                
                ${lowScores}
                
                ### All Scores:
                - Performance: ${scores.Performance}%
                - Accessibility: ${scores.Accessibility}%
                - SEO: ${scores.SEO}%
                - Best Practices: ${scores['Best Practices']}%
                
                ### Next Steps
                1. Review the detailed report in the workflow artifacts
                2. Focus on improving the low-scoring areas
                3. Consider running Lighthouse locally to test improvements
                
                [View detailed report](${process.env.GITHUB_SERVER_URL}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})`,
                labels: ['performance']
              });
            } catch (error) {
              console.log('Error creating issue:', error.message);
              core.setFailed('Failed to create performance issue');
            } 